---
layout: post
title: Machine Learning desde una perspectiva Probabilística Pt.2
tags:
  - machine-learning
  - bayes
---
{% include katex.html %}

{% katexmm %}

## Introducción
Según Wikipedia, la Apofenia "es la experiencia que consistente en ver patrones, conexiones o ambos en sucesos aleatorios o en datos sin sentido". Al entrenar un modelo de *Machine Learning*, ¿cómo sabemos que nuestro modelo no sufre de Apofenia? Consideremos la siguiente serie de puntos.

![dots](https://i.imgur.com/h6xnKFk.png)

A primer vistazo, podríamos concluir que a nuestros ojos no existe patrón alguno y, por lo tanto, no existe una relación; por otro lado, podríamos hacernos la idea de que realmente existe un patrón y está dado por alguna línea o curva. Para el segundo caso, podríamos tratar de escribir una ecuación que explique la relación entre el eje  $x$ y el eje $y$. Consideremos, por ejemplo, queremos modelar los datos mediante la siguiente función:

$$
\begin{aligned}
    \hat y(x) &= w_0 + w_1 x + w_2 x^2 + w_3 x^3\\
                &= {\bold w}^T\phi(\bold x)
\end{aligned}
$$

con $\bold w\in \mathbb{R}^3, \bold x\in\mathbb{R}$ y $\phi(x) = (1, x, x^2, x^3)^T$.

Denotamos las observaciones en este ejemplo como una base de datos de la forma  $\mathcal D=\{(x_n, t_n) | x_n\in\mathbb{R}, t_n\in\mathbb{R}\}_{n=1}^N$. De igual manera, denotaremos $\bold t\in\mathbb{R}^N$ el vector de variables dependientes y por $\boldsymbol\Phi\in\mathbb{R}^{N\times M}$ la matriz resultante de aplicar la transformación $\phi$ a cada elemento $x_n$. En este sentido,

$$
    \boldsymbol\Phi = \begin{bmatrix}
    \rule{2.5ex}{0.5pt} & \phi(x_1)^T & \rule{2.5ex}{0.5pt} \\
    & \vdots & \\
    \rule{2.5ex}{0.5pt} & \phi(x_N)^T & \rule{2.5ex}{0.5pt} \\
    \end{bmatrix}
$$

Dado que asumimos una relación entre los datos dada por $\hat y$, el resultado de esta relación depende únicamente del  vector $\bold w$.  En el [post pasado]([https://gerdm.nabla.mx/proba-ml-1/](https://gerdm.nabla.mx/proba-ml-1/)) vimos dos maneras de estimar $\bold w$: si asumimos que la variable objetivo $t$, condicionada a $x$, se distribuye de la forma $t|x \sim \mathcal{N}(\bold w^T\phi(\bold x), \beta^{-1})$, maximizar la verosimilitud $p(\bold t | \bold x, \bold w,\beta)$ respecto a $\bold w$ es equivalente a ajustar un modelo de regresión lineal en el cual  $\bold w^* = \argmin_\bold w ||\bold t - \boldsymbol\Phi\bold w||^2$. Por otro lado, maximizar la distribución *a posteriori* $p(\bold w | \mathcal D) \propto p(\bold w)p(\bold t|\bold x,\bold w)$ respecto a $\bold w$ asumiendo que $p(\bold w) = \mathcal{N}(\bold w | \bold 0, \alpha^{-1}\bold I)$ es equivalente a ajustar un modelo *Lasso* con parámetro $\lambda = \frac{\beta}{\alpha}$.

Dicho de otra manera, encontrar $\bold w$ óptima por medio de una regresión lineal considera únicamente la evidencia de que $\bold w$ fue generado por $\mathcal D$, es decir, la verosimilitud; por otro lado, un modelo *Lasso* considera tanto la verosimilitud sobre $\bold w$, así como una creencia *a priori* de que cada peso dentro de $\bold w$, en promedio, no explica la relación entre $t$ y $x$.

Regresando a nuestra base de datos $\mathcal D$, ajustemos ahora una regresión lineal y un *Lasso* con $\lambda = 1$.

![linear_models](https://i.imgur.com/FUQisGG.png)

Dada la gráfica anterior parecería que el modelo encuentra un patrón en los datos, pero esto no necesariamente nos garantiza que hayamos encontrado una relación. Dos maneras de estimar que tan bien ajustamos el modelo a los datos estarían dadas por medio de una validación cruzada (CV) o calcular la $R^2$ ajustada del modelo. Una tercera manera de analizar esta bondad de ajuste sería calculando la incertidumbre que tiene el modelo sobre los parámetros ajustados.

## Midiendo Incertidumbre
Recordemos que un modelo *Lasso* maximiza la distribución *a posteriori* $p(\bold w | \mathcal D)$  respecto a $\bold w$. Esto es equivalente a encontrar la moda de $p(\bold w | \mathcal D)$. Calcular únicamente la moda nos priva de *cuestionar* al modelo sobre varios estadísticos que podrían ser de interés. Por ejemplo, saber la variación total de la matriz de covarianza o calcular probabilidades dentro de los parámetros para explicar los coeficientes del modelo y el impacto que estos tienen sobre la variable $t$.

Con el fin de obtener una distribución de probabilidad, retomemos la forma de la distribución *a posteriori* de los parámetros dado por

$$
    p(\bold{w}|\mathcal{D}) \propto p(\bold{w})p(\mathcal{D}|\bold{w})
$$

Donde la distribución *a priori* de los coeficientes $\bold w$ se distribuyen de la forma $\bold w \sim \mathcal{N}(\bold m_0, \bold S_0)$. Por otro lado tenemos que

$$
p(\mathcal{D}|\bold{w}) = \prod_{n=1}^N \mathcal{N}\left(t_n | \bold w^T \phi(\bold x_n), \beta^{-1}\right)
$$

Subsecuentemente vemos que para la distribución *a posteriori* se cumple:

$$
\begin{aligned}
    p(\bold{w}|\mathcal{D}) &\propto p(\bold{w})p(\mathcal{D}|\bold{w})  \\
    &= \mathcal{N}(\bold w | \bold m_0, \bold S_0) \prod_{n=1}^N \mathcal{N}(t_n | \bold w^T \boldsymbol\phi, \beta^{-1})\\
    &\propto \exp\left(-\frac{1}{2}(\bold w - \bold m_N)^T \bold S_N(\bold w - \bold m_N)\right) 
\end{aligned}
$$

Con 
* $\bold S_N^{-1} = S_0^{-1} + \beta \boldsymbol\Phi^T\boldsymbol\Phi$ y
*  $\bold m_N = \bold S_N\left(\bold S_0 \bold m_0 + \beta\boldsymbol\Phi^T\bold t\right)$

Por lo tanto, tendríamos que la distribución *a posteriori* de los coeficientes del modelo $\bold w$ se distribuyen Normal con media $\bold m_N$ y matriz de covarianza $\bold S_N$. Visto de otra manera, dado que $\bold w$ es una variable aleatoria, evaluar $\hat y(x)$ múltiples veces resultaría en diferentes estimaciones. Esta es una primera bondad de un modelo probabilístico pues nos indica la confianza, por medio de desviaciones estándar, que está un parámetro de ser útil.

 Consideremos, por ejemplo, 20 muestras de $\bold w | \mathcal D$ con $p(\bold w) = \mathcal{N}(\bold w | \bold 0, \alpha^{-1}\bold I)$. Evaluando estas 20 muestras dentro de $\hat y$ resulta en la siguiente gráfica

![one_samp](https://i.imgur.com/F9CNBO2.png)


Cada línea gris de la gráfica anterior representa un posible vector $\bold w$ que pudo haber generado los datos. Cerca de las colas, los trazos muestreados arrojan diferentes caminos que pudieron haber generado la curva con muy variadas direcciones, es decir, el modelo tiene poca confianza de la tendencia que debería seguir. Por otro lado, entre las dos colas vemos que el modelo no oscila drásticamente y marca una tendencia de punta a punta. Numéricamente, evaluar la variación de las estimaciones $\hat y(x)$ dependen de la **distribución predictiva** dada por 

$$
\begin{aligned}
    p(t|\mathcal{D},\bold{x},\alpha,\beta) &= \int p(t, \bold{w}| \mathcal{D},\bold{x}, \alpha,\beta) d\bold{w}\\
        &= \int p(\bold{w}|\alpha, \mathcal{D})p(t|\bold{x}, \bold{w}, \beta) d\bold{w}
\end{aligned},
$$

y cuya evaluación lo dejaremos para otra ocasión.

Otra de las bondades de estar trabajando con un modelo probabilístico es el poder actualizar los parámetros a medida que contamos con mayor información. Con esto, dado unos coeficientes iniciales $\bold m_0$ y $\bold S_0$, podríamos calcular la distribución a-posteriori de observar $N$ datos y obtener $\bold m_N$ y $\bold S_N$. Si llegáramos a adquirir $M$ nuevos puntos, en vez de actualizar todo el modelo desde cero, podríamos partir con la distribución *a priori* dado por los parámetros $\bold m_N$, $\bold S_N$ y actualizarlos para obtener $\bold m_{N + M}$ y $\bold S_{N + M}$. En la siguiente gráfica se ilustra esta idea: a cada paso de entrenamiento actualizamos el modelo con una nueva observación.


![muestras de la distribución a posteriori](https://i.imgur.com/mlbYjf8.gif)


{% endkatexmm %}

### Referencias
* BISHOP, CHRISTOPHER M. PATTERN RECOGNITION AND MACHINE LEARNING. SPRINGER-VERLAG NEW YORK, 2016.
