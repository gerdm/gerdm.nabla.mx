---
layout: post
title: Machine Learning desde una perspectiva Probabilística Pt.1
tags:
  - machine-learning
  - bayes
---
{% include katex.html %}

{% katexmm %}

$$
	p(t|\mathcal{D},\bold{x},\alpha,\beta) =\int p(\bold{w}|\alpha, \mathcal{D})p(t|\bold{x}, \bold{w}, \beta) d\bold{w}
$$

Una de las gráficas que mayor recuerdo aprendiendo sobre la regresión lineal  se encontraba en un libro de econometría. En la imagen se podían observar tres factores: puntos muestrales, la curva sobre la cual los puntos fueron generados y distribuciones Gaussianas sobre intervalos de la curva. La finalidad de la gráfica era ilustrar que la estimación de la regresión lineal dada una observación es igual a la esperanza condicional de la distribución de la variable que se espera modelar dada una observación.

![linear model plot](https://i.imgur.com/7rDEvQp.png)


La conclusión de aquel capítulo era demostrar que un modelo de regresión lineal es de gran ayuda si la *distribución condicional* de nuestros datos se comporta normal y presenta homocedasticidad (varianza constante); pero, ¿qué sucede si esto no se cumple? Nuestra distribución podría tener varianza no constante o ni siquiera distribuirse Normal. De igual manera, ¿qué hacemos si no es de nuestro interés conocer una esperanza?

Para motivar estas preguntas, consideremos el ejemplo de estar modelando el rendimiento de una acción para hacer un *trade*. Supongamos que $\bold x$ es un vector que, asumimos, impacta al rendimiento $t$. De ajustar una regresión lineal sobre $t$ considerando $\bold x$, al hacer una predicción sobre $\bold x$, el modelo únicamente nos proporcionaría $\mathbb{E}[t|\bold x]$. Si $\mathbb{E}[t|\bold x] > 0$, podríamos asumir que el _trade_ tiene una esperanza de ser rentable, es decir, después de ejecutar una infinidad de veces la estrategia, esperaríamos tener un retorno positivo. 

Lamentablemente en el día a día no contamos con infinitas oportunidades para obtener un retorno positivo, por lo que deberíamos adoptar ciertas medidas de riesgo para la posición que queremos tomar. Por ejemplo, si bien $\mathbb{E}[t|\bold x] > 0$, ¿cuál es la probabilidad de obtener una pérdida ($\mathbb P(t<0|\bold x)$)? La siguiente gráfica representa esta idea. Ambas distribuciones tienen media 1, pero difieren en varianza. Para este ejemplo, $\mathbb{P}_1(X \leq 0) \approx 0.16$; mientras que $\mathbb	{P}_2(X \leq 0) \approx 0.05$.

![normals](https://i.imgur.com/1Ee6RSx.png)

En general, lo que buscamos es una completa distribución de probabilidad condicional $p(t|x)$ sobre la cuál podamos cuestionar al modelo.

En este *post*  introduciremos las bases necesarias para entender un modelo de _Machine Learning_ desde una perspectiva probabilística. Motivaremos el uso de máxima verosimilitud como aplicación en *Machine Learning* y el uso de la _regularización_ de parámetros como consecuencia de incluir creencias _a-priori_.

## Adaptando un modelo probabilístico

Consideremos una base de datos $\mathcal{D}=\{(\bold{x}_n, t_n)\}_{n=1}^N$. Nuestro objetivo será estimar el valor de $t_n$ dado $\bold{x}_n$. Supongamos que $\forall n.t_n\sim \mathcal{N}(y(\bold{x},\bold{w}), \beta^{-1})$ tal que $y: \mathbb{R}^M\to\mathbb{R}$ es una función que transforma $\bold{x}$ dado un vector $\bold{w}$[^1].  Supongamos de igual manera que conocemos el valor de $\beta\in\mathbb{R}^+ / \{0\}$, la *precisión* del modelo.

[^1]: Un ejemplo muy sencillo sería asumir que $y(\bold x, \bold x) = \bold w^T \bold x$. En cuyo caso tendríamos una regresión lineal, pero este puede ser tan complejo como deseemos.

Dado un valor objetivo $t_n$, lo único que sabemos sobre este es su vector asociado $\bold{x}_n$, por lo que nos restaría preguntar, ¿qué vector $\bold{w}$ le pertenece a nuestro modelo?

Para encontrar $\bold{w}$, asumiremos que tiene una distribución de probabilidad asociada y, aunque desconocemos cuál es, tenemos alguna creencia sobre cuál podría ser su valor real. Esta creencia estará integrada en nuestro modelo como otra distribución de probabilidad a la cual conoceremos como distribución *a-priori*.

Luego, dada la información de la base de datos $\mathcal D$ nos gustaría *actualizar* nuestra creencia sobre $\bold w$.  Esta última oración es fácil de materializar en una ecuación usando el teorema de Bayes,

$$
	p(\bold{w}|\mathcal{D}) = \frac{p(\bold{w})p(\mathcal{D}|\bold{w})}{\int p(\bold{w})p(\mathcal{D}|\bold{w}) d\bold{w}}
$$

Donde,
* $p(\bold{w})$ es nuestra distribución a priori;
* $p(\mathcal{D}|\bold{w})$ es la verosimilitud de probabilidad; y
* $\int p(\bold{w})p(\mathcal{D}|\bold{w}) d\bold{w}$ es una constante de integración (cuya función es normalizar la distribución).

Dejando la constante de integración a un lado, podemos escribir la distribución *a-posteriori*: un término proporcional a nuestras creencias *a priori* multiplicado por la verosimilitud de los datos, como:

$$
	p(\bold{w}|\mathcal{D}) \propto p(\bold{w})p(\mathcal{D}|\bold{w})
$$

Con este resultado podemos ver que $\bold w$ no es única. De hecho, puede tomar cualquier valor dado por el dominio de la distribución *a posteriori*.

Regresando a nuestro modelo original $t\sim \mathcal{N}(y(\bold{x},\bold{w}), \beta^{-1})$, vemos que la distribución sobre $t$ está en función de $\bold w$ que a su vez es una variable aleatoria, es decir, no toma un único valor. Esto implicaría que para calcular $p(t|x)$ tendríamos que marginalizar sobre todos los posibles valores de $\bold w$:

$$
\begin{aligned}
	p(t|x) &= \int p(t,\bold w|x) d\bold w\\
	&= \int p(\bold w) p(t|x, \bold w) d\bold w
\end{aligned}
$$

La ecuación dada por $p(t|x)$ estaría incompleta de no considerar la base de datos $\mathcal D$, por lo que realmente nos interesaría conocer la distribución $p(t|\mathcal D, \bold x)$:

$$
\begin{aligned}
	p(t|\mathcal D, \bold x) &= \int p(t, \bold w|\mathcal D, \bold x) d\bold w\\
	&= \int p(\bold w|\mathcal D) p(t|\bold x, \bold w) d\bold w
\end{aligned}
$$

Esta última ecuación nos indica que para poder encontrar la distribución sobre una $t$ no observada, dada la base de datos $\mathcal D$ y un vector $\bold{x}$, tendríamos que encontrar la distribución resultante de marginalizar sobre $\bold w$ que a su vez requiere encontrar la distribución a posteriori de $\bold w$. Este cálculo no únicamente se lee complicado, en muchas ocasiones lo es. Sin embargo, entender esta idea es la clave para crear un modelo probabilístico.

## Máxima verosimilitud (ML) y la regresión lineal
Antes de llegar a un modelo completamente probabilístico, supongamos por el momento que no estamos interesados en modelar toda una distribución $p(\bold w |\mathcal D)$; únicamente nos interesa obtener la $\bold w$ que mayor evidencia tenga de serlo. La manera estadística de lograr esto es por medio de la verosimilitud, la cual indica que tan creíble es que los datos $\mathcal D$ hayan sido generados por $\bold w$. Encontrar $\bold w_{ML} = \argmax_{\bold w}p(\mathcal D | \bold w)$  sería encontrar la $\bold w$ con mayor evidencia de haber generado $\mathcal D$.

Para encontrar $\bold w_{ML}$, asumiremos que la verosimilitud $p(\mathcal D| \bold w)$ tiene muy baja varianza y se centra al rededor de un único $\bold w_{ML}$. En este caso podemos asumir que la distribución verosimilitud de los datos es muy puntiaguda. En otras palabras, queremos encontrar $\bold w$ por máxima verosimiltud.

La verosimilitud está dada por

$$
\begin{aligned}
p(\mathcal D | \bold w) &= \prod_{n=1}^N p(t_n|{\bold w}, \bold x_n)\\
&= \prod_{n=1}^N \mathcal N(t_n|y(\bold w, \bold x_n), \beta^{-1}) \\
&= \left(\frac{\beta}{\sqrt{2\pi}}\right)^N\exp\left(-\frac{\beta}{2}\sum_{n=1}^N(t_n - y(\bold w, \bold x_n))^2\right)
\end{aligned}
$$

Entonces,

$$
\begin{aligned}
\bold w_{ML} &= \argmax_{\bold w} p(\mathcal D | \bold w) \\
&= \argmax_{\bold w}\log p(\mathcal D | \bold w) \\
&= \argmax_{\bold w} - \frac{\beta}{2}\sum_{n=1}^N\left(t_n - y(\bold w, \bold x_n)\right)^2\\
&= \argmin_{\bold w}  \frac{1}{2}\sum_{n=1}^N\left(t_n - y(\bold w, \bold x_n)\right)^2
\end{aligned}
$$

Si $y(\bold w, \bold x) = \bold w^T \bold x$, vemos que minimizar el negativo de la log-verosimilitud es encontrar  $\bold w_{ML}$ que minimize el error cuadrático, es decir, una regresión lineal.

## Máximo a-Posteriori (MAP)
¿Qué sucede si la suposición de una verosimilitud muy puntiaguda no se cumple o existen variables dentro de nuestro modelo que son redundantes? Consideremos nuevamente la distribución *a posteriori* de nuestro modelo:

$$
	p(\bold{w}|\mathcal{D}) \propto p(\bold{w})p(\mathcal{D}|\bold{w})
$$

Podemos introducir una creencia *a-priori* de que todos los pesos $\bold  w_i$ se centran al rededor del $0$ como una distribución $\mathcal N(\bold 0, \alpha^{-1} I)$. En este caso, de existir suficiente evidencia en la verosimilitud de que un parámetro $\bold w_i$ no es cero, actualizaríamos nuestras creencias. Con esto

$$
\begin{aligned}
\bold w_{\text{MAP}} &= \argmax_{\bold w} p(\bold{w})p(\mathcal{D}|\bold{w})\\
&=\argmax_{\bold w} \log p(\bold{w})+\log p(\mathcal{D}|\bold{w}) \\
&= \argmax_{\bold w} - \frac{\beta}{2}\sum_{n=1}^N\left(t_n - y(\bold w, \bold x_n)\right)^2 \\&\qquad -\frac{\alpha}{2}\sum_{m=1}^M \bold w^T \bold w\\
&= \argmin_{\bold w}  \beta||\bold t - \bold y||^2  +\alpha ||\bold w||^2
\end{aligned}
$$

Donde denotamos $\bold y = \big(y(\bold w, \bold x_1), \ldots, y(\bold w, \bold x_N)\big)^T$, $\bold t = \big(t_1, \ldots, t_N\big)$.

Definiendo $\lambda = \alpha/\beta$ formulamos  nuestro problema como
$$
	\bold w_{\text{MAP}} = \argmin_{\bold w}  ||\bold t - \bold y||^2  +\lambda ||\bold w||^2
$$

Si $y(\bold w, \bold x) = \bold w^T \bold x$, encontrar $\bold w_{\text{MAP}}$ se conoce como *Ridge regression*. En terminología de *Machine Learning*, el término $||\bold t - \bold y||^2  +\lambda ||\bold w||^2$ es una función de costos; donde $\lambda ||\bold w||^2$ es conocido como el término de regularización.

## En conclusión
Un modelo de regresión lineal con o sin regularización es equivalente encontrar la moda de la distribución *a-posteriori*  que surge de condicionar el parámetro $\bold w$ a nuestros datos observados asumiendo que la esperanza condicional de nuestros datos está dada por $\mathbb E[t|\bold x, \bold w] = \bold w^T \bold x$. 

En una segunda parte, analizaremos más a detalle las implicaciones de trabajar con un modelo totalmente probabilístico: sus ventajas, desventajas y la manera de usar Python para trabajar con estos.

{% endkatexmm %}

### Referencias
* BISHOP, CHRISTOPHER M. PATTERN RECOGNITION AND MACHINE LEARNING. SPRINGER-VERLAG NEW YORK, 2016.
